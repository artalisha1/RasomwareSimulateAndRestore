# -*- coding: utf-8 -*-
"""SimulateRansom+Restore_Periodic_V2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q-YJECA8KNY0a5Lmo9pTaDZ2j6aCb4dS

#Restic Ransomware Simulation¬†&¬†Auto‚ÄëRecovery¬†Lab

Integrates automated Restic snapshots, simulates a ransomware attack, and then verifies and restores the latest clean baseline‚Äîall without manual intervention.

##Summary

This notebook spins up a self‚Äëcontained playground that

##Step 0: Persist everything to Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')          # Skip this cell if you don't need persistence

# Choose a root dir that survives VM resets if you mounted Drive
ROOT = "/content/drive/MyDrive/ransomware_lab"  # or "/content" if Drive not mounted
!mkdir -p $ROOT

"""##Step 1: Install Tools"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# sudo apt-get update -qq
# sudo apt-get install -y restic gnupg tree

# Commented out IPython magic to ensure Python compatibility.
# #Install extra utilities
# %%bash
# sudo apt-get install -y inotify-tools   # for near real‚Äëtime backup
# pip install --quiet watchdog            # Python file‚Äëwatcher library

"""##Step 2: Configure Restic Repo"""

import os, subprocess, textwrap, getpass, json, pathlib, shutil, time

# Change these if you like
DATA_DIR      = f"{ROOT}/victim_data"
RESTIC_REPO   = f"{ROOT}/backup_repo"
RESTORE_DIR   = f"{ROOT}/restore"
os.makedirs(DATA_DIR,   exist_ok=True)
os.makedirs(RESTORE_DIR, exist_ok=True)

# One‚Äëliner to set the repo password (DON'T lose it!)
os.environ["RESTIC_PASSWORD"] = "colab‚Äëdemo‚Äësuper‚Äësecret"  # choose a strong one IRL

# Initialize repository once
if not pathlib.Path(RESTIC_REPO, "config").exists():
    !restic -r $RESTIC_REPO init

"""##Step 3: Generate sample "production" files"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash -s "$DATA_DIR"
# TARGET=$1
# mkdir -p "$TARGET/docs" "$TARGET/images"
# 
# # simple text data
# echo "Quarterly revenue: \$123,456"  > "$TARGET/docs/report_Q1.txt"
# echo "User list (PII redacted)"      > "$TARGET/docs/users.txt"
# 
# # simulate binary data
# head -c 1M </dev/urandom > "$TARGET/images/raw_sensor_dump.bin"
# 
# tree -h "$TARGET"

"""##Step 4: Define Helper to Print List of Snapshots"""

import subprocess
import sys
import os

def print_current_snapshots(restic_repo: str):
    """
    Prints the list of snapshots in the specified Restic repository.
    Relies on RESTIC_PASSWORD env var for authentication.
    """
    common_args = ["restic", "--repo", restic_repo]

    try:
        # Use --no-lock for faster listing if appropriate
        output = subprocess.check_output(
            common_args + ["snapshots", "--no-lock"],
            env=os.environ,
            text=True
        )
        print("üîç Current snapshots in repository:")
        print(output)
    except subprocess.CalledProcessError as e:
        err = e.stderr if hasattr(e, 'stderr') and e.stderr else str(e)
        print("‚ùó Error listing snapshots:", err, file=sys.stderr)

"""##Step 5: Define Baseline Snapshot Helper"""

import subprocess
import json
import threading
import time
from datetime import datetime

def run(cmd: list[str]) -> subprocess.CompletedProcess:
    """
    Run the given command (printing it) and return a CompletedProcess
    (with .stdout/.stderr) for downstream parsing.
    """
    print(f"$ {' '.join(cmd)}")
    return subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        check=True
    )

def get_baseline_snapshot_ids(restic_repo: str) -> list[str]:
    """
    Return a list of all snapshot IDs (short form) tagged 'baseline' in the repo.
    """
    proc = run(["restic", "-r", restic_repo, "snapshots", "--tag", "baseline", "--json"])
    snaps = json.loads(proc.stdout)
    # each snap has keys like "short_id", "time", etc.
    return [snap["short_id"] for snap in snaps]

def print_diff_details(diff: dict) -> None:
    """
    Pretty-print categorized diff results.
    """
    blocks = [
        ("‚ûï Added", diff.get("added", [])),
        ("‚úèÔ∏è Modified", diff.get("modified", [])),
        ("üóëÔ∏è Removed", diff.get("removed", [])),
        ("üßæ Metadata-only", diff.get("meta", [])),
    ]
    any_printed = False
    for title, items in blocks:
        if items:
            any_printed = True
            print(title + ":")
            for p in items:
                print(f"  ‚Ä¢ {p}")
    if not any_printed:
        print("üîç No changes detected.")

import re
def get_diff_details(old_id: str, new_id: str, restic_repo: str) -> dict:
    """
    Parse `restic diff old new` and return categorized path lists.
    Supports both 'A/M/R/U path' and '+/- path' formats.
    """
    proc = run(["restic", "-r", restic_repo, "diff", old_id, new_id])

    added, modified, removed, meta = [], [], [], []

    for raw in proc.stdout.splitlines():
        line = raw.strip()
        if not line:
            continue
        # Skip headers/summaries
        if ":" in line and line.split(":", 1)[0].lower() in {
            "comparing", "files", "dirs", "added files", "removed files",
            "modified files", "added dirs", "removed dirs", "modified dirs"
        }:
            continue

        # Format 1: "A path", "M path", "R path", "U path"
        m = re.match(r"^([AMRU])\s+(.+)$", line)
        if m:
            code, path = m.group(1), m.group(2)
            if code == "A": added.append(path)
            elif code == "M": modified.append(path)
            elif code == "R": removed.append(path)
            elif code == "U": meta.append(path)
            continue

        # Format 2: "+ path" (added), "- path" (removed)
        m = re.match(r"^([+\-])\s+(.+)$", line)
        if m:
            code, path = m.group(1), m.group(2)
            if code == "+": added.append(path)
            elif code == "-": removed.append(path)
            continue

        # If we reach here it's an unrecognized line; ignore
        # print("DEBUG unparsed diff line:", line)

    return {"added": added, "modified": modified, "removed": removed, "meta": meta}

def ensure_baseline_snapshot(data_dir: str, restic_repo: str) -> None:
    """
    1) If no baseline exists, take one and return.
    2) Otherwise:
         a) Record old_id = latest baseline snapshot.
         b) Run `restic backup --tag baseline` to create new snapshot.
         c) Let new_id = ID of that new snapshot.
         d) Call get_diff_files(old_id, new_id):
            ‚Ä¢ if empty ‚Üí forget/prune new_id (skip)
            ‚Ä¢ else    ‚Üí print_changed_files(paths) and keep new_id
    """
    # 1) List existing baselines, pick latest by timestamp
    proc0 = run(["restic", "-r", restic_repo, "snapshots", "--tag", "baseline", "--json"])
    snaps = json.loads(proc0.stdout)
    snaps.sort(key=lambda s: s["time"])
    if not snaps:
        print("üì¶ No baseline found ‚Äî creating initial baseline.")
        run(["restic", "-r", restic_repo, "backup", data_dir, "--tag", "baseline"])
        print(f"‚úÖ Baseline created at {datetime.now().isoformat()}")
        return

    old_id = snaps[-1]["short_id"]

    # 2) Create the new snapshot
    print("‚è≥ Running backup to test for real changes‚Ä¶")
    proc = run(["restic", "-r", restic_repo, "backup", data_dir, "--tag", "baseline", "--json"])
    # parse the summary JSON for new_id
    new_id = None
    for line in proc.stdout.splitlines():
        try:
            msg = json.loads(line)
        except json.JSONDecodeError:
            continue
        if msg.get("message_type") == "summary":
            new_id = msg["snapshot_id"]
            break
    if new_id is None:
        raise RuntimeError("Could not find summary in restic JSON output")

    # 3) Diff old‚Üínew to get the **true** list of changed files
    # changed = get_diff_files(old_id, new_id, restic_repo)
    # if not changed:
    diff = get_diff_details(old_id, new_id, restic_repo)
    changed_count = sum(len(v) for v in diff.values())
    if changed_count == 0:
        print(f"‚ö†Ô∏è No real file-tree changes; forgetting baseline {new_id}")
        run(["restic", "-r", restic_repo, "forget", new_id, "--prune"])
        print("‚úÖ Skipped baseline (no real changes).")
    else:
        print(f"‚úÖ Real changes detected ({changed_count} paths); keeping {new_id}")
        print_diff_details(diff)

"""##Step 6: Define Periodic Baseline Scheduler"""

import threading
import time

def start_periodic_baseline(data_dir: str, restic_repo: str, interval: int):
    """
    Spawns a background thread that re-tags the latest state as a new baseline
    every `interval` seconds by calling ensure_baseline_snapshot().
    """
    stop_event = threading.Event()
    def loop():
        while True:
            ensure_baseline_snapshot(data_dir, restic_repo)
            # time.sleep(interval)
            stop_event.wait(interval)

    t = threading.Thread(target=loop, daemon=True)
    t.start()
    print()
    print(f"üïí Started periodic baseline thread (every {interval}s)")
    return stop_event, t

# start_periodic_baseline(DATA_DIR, RESTIC_REPO, interval=15)
stop_ev, thread = start_periodic_baseline(DATA_DIR, RESTIC_REPO, interval=15)
time.sleep(5)

"""##Step 7: Define Helper to Restore Latest Baseline Snapshot that is Readable"""

import subprocess
import os
import pathlib
import shutil
import sys
import json
import tempfile
from datetime import datetime

def restore_latest_clean_baseline(restic_repo: str, restore_dir: str):
    """
    Attempts to restore the latest clean baseline snapshot.
    Iterates through snapshots tagged 'baseline' in reverse chronological order,
    restores to a temporary directory, verifies critical files, moves data,
    and returns the restored snapshot ID.
    """
    print("üîç Searching for clean baseline snapshots...")

    # 1. List baseline snapshots
    try:
        proc = subprocess.run(
            ["restic", "-r", restic_repo, "snapshots", "--tag", "baseline", "--json"],
            capture_output=True, text=True, check=True, env=os.environ
        )
        snapshots = json.loads(proc.stdout)
    except subprocess.CalledProcessError as e:
        print("‚ùå Failed to list baseline snapshots:", e.stderr.strip(), file=sys.stderr)
        return False, None

    if not snapshots:
        print("‚ùå No baseline snapshots found.")
        return False, None

    # 2. Sort by timestamp descending
    for snap in snapshots:
        snap["parsed_time"] = datetime.fromisoformat(snap["time"].rstrip("Z"))
    snapshots.sort(key=lambda s: s["parsed_time"], reverse=True)

    restore_path = pathlib.Path(restore_dir)
    tmp_root = pathlib.Path(tempfile.mkdtemp(prefix="restic_tmp_"))

    try:
        # 3. Try each snapshot until valid
        for snap in snapshots:
            sid = snap["id"]
            print(f"üïµÔ∏è Trying snapshot {sid}...")

            tmp_dir = tmp_root / sid
            if tmp_dir.exists():
                shutil.rmtree(tmp_dir)
            tmp_dir.mkdir(parents=True)

            # Restore
            try:
                subprocess.run(
                    ["restic", "-r", restic_repo, "restore", sid, "--target", str(tmp_dir)],
                    capture_output=True, text=True, check=True
                )
            except subprocess.CalledProcessError as e:
                print(f"‚ö†Ô∏è Restore failed for {sid}: {e.stderr.strip()}")
                continue

            # Locate victim_data
            victim_dirs = list(tmp_dir.rglob("victim_data"))
            if not victim_dirs:
                print(f"‚ùå victim_data not found in {sid}")
                continue
            victim_path = victim_dirs[0]

            # Verify critical file readability
            critical = victim_path / "docs" / "report_Q1.txt"
            if not critical.exists():
                print(f"‚ùå report_Q1.txt missing in {sid}")
                continue
            try:
                with open(critical, 'r') as f:
                    f.read(1)
            except Exception as e:
                print(f"‚ùå Cannot read report_Q1.txt in {sid}: {e}")
                continue

            # 4. Prepare restore_dir
            if restore_path.exists():
                shutil.rmtree(restore_path)
            restore_path.mkdir(parents=True)

            # Move contents
            for item in tmp_dir.iterdir():
                shutil.move(str(item), str(restore_path / item.name))

            print(f"‚úÖ Restored clean baseline {sid} into {restore_dir}")
            return True, sid

        print("‚ùå No clean baseline snapshot found.")
        return False, None

    finally:
        shutil.rmtree(tmp_root)

"""##Step 8: 15 Seconds Pause"""

import time, subprocess, os
print("‚åõ¬†Sleeping 15s so real‚Äëtime activity accumulates ‚Ä¶")
time.sleep(15)
print_current_snapshots(RESTIC_REPO)

"""##Step 9: Validate the Accuracy of Baseline Function
Create a File, check baseline snapshots

Delete the File, check baseline snapshots
"""

# 1. Show current baselines
print("‚ñ∂Ô∏è Before Adding File:")
print_current_snapshots(RESTIC_REPO)

# 2. Create a dummy change
new_file = os.path.join(DATA_DIR, f"verify_{int(time.time())}.txt")
with open(new_file, "w") as f:
    f.write("trigger baseline\n")

print(f"üìù Created: {new_file}")

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# VICTIM_PATH="/content/drive/MyDrive/ransomware_lab/victim_data"
# tree -h "$VICTIM_PATH"

time.sleep(10)
# 3. Show baselines again
print("‚ñ∂Ô∏è After Adding File:")
print_current_snapshots(RESTIC_REPO)

import os, glob, json, time
# 4. Find and Delete the text file
matches = glob.glob(os.path.join(DATA_DIR, "verify_*.txt"))
if not matches:
    print("‚ùå No verify_*.txt found. Create one first, then rerun.")
else:
  target = max(matches, key=os.path.getmtime)
  rel = os.path.relpath(target, DATA_DIR)
  print(f"üóÇÔ∏è Target file to delete: {rel}")
  #Delete the file
  os.remove(target)
  print(f"üóëÔ∏è Deleted: {rel}")

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# VICTIM_PATH="/content/drive/MyDrive/ransomware_lab/victim_data"
# tree -h "$VICTIM_PATH"

time.sleep(10)
# 5. Show baselines again
print("‚ñ∂Ô∏è After Deleting File:")
print_current_snapshots(RESTIC_REPO)

"""##Step 10: Simulate Ransomware attack

###Define Helper to Mark Simulated Ransomware Attack in Snapshots
"""

import subprocess, os

def mark_attack_snapshot(data_dir: str, restic_repo: str):
    """
    Takes a Restic backup of data_dir and tags it 'attack' to mark
    the moment of the simulated ransomware event.
    """
    common_args = ["restic", "--repo", restic_repo]
    print("‚ö†Ô∏è  Ransomware attack simulated ‚Äî taking 'attack' snapshot‚Ä¶")
    subprocess.run(
        common_args + ["backup", data_dir, "--tag", "attack"],
        check=True, env=os.environ
    )
    print("‚úÖ  'attack' snapshot complete.")

"""###Encrypt the files and Simulate Attack"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash -s "$DATA_DIR"
# VICTIM=$1
# # Encrypt *.txt as a stand‚Äëin for ransomware, then delete originals
# cd "$VICTIM/docs"
# for f in *.txt; do
#   openssl enc -aes-256-cbc -md sha256 -salt -in "$f" -out "${f}.enc" -pass pass:evil123
#   shred -u "$f"
# done
# echo "After attack:"
# tree -h "$VICTIM"

##mark the attack in Restic
mark_attack_snapshot(DATA_DIR, RESTIC_REPO)

time.sleep(10)
print_current_snapshots(RESTIC_REPO)

"""##Step 11: Attempt to Read
Will fail
"""

import pathlib, sys

plaintext = pathlib.Path(DATA_DIR) / "docs" / "report_Q1.txt"   # original file path

try:
    text = plaintext.read_text()          # should raise FileNotFoundError
    print("‚ùå  UNEXPECTED: plaintext still readable!", text[:100])
    sys.exit(1)
except (FileNotFoundError, PermissionError):
    print("‚úÖ  Expected failure: plaintext is gone or unreadable ‚Äî ransomware succeeded.")

"""##Step 12: Restore the Latest Clean Snapshot"""

#List all snapshots
print_current_snapshots(RESTIC_REPO)

success, restored_id = restore_latest_clean_baseline(RESTIC_REPO, RESTORE_DIR)

"""##Step 13: Verify Restored File Exists and Matches Expected Content"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# # 1. Point to your restore directory
# export RESTORE_DIR="/content/drive/MyDrive/ransomware_lab/restore"
# 
# # 2. Locate the nested victim_data folder
# VICTIM_PATH=$(find "$RESTORE_DIR" -type d -name victim_data | head -n1)
# if [ -z "$VICTIM_PATH" ]; then
#   echo "‚ùå Could not find victim_data under $RESTORE_DIR"
#   exit 1
# fi
# 
# echo "‚úÖ Restored data is at: $VICTIM_PATH"
# 
# # 3. List the docs you recovered
# echo; echo "Recovered docs:"
# tree -h "$VICTIM_PATH/docs" | sed -n '1,5p'
# 
# # 4. Show the contents of report_Q1.txt
# echo; echo "Contents of report_Q1.txt:"
# cat "$VICTIM_PATH/docs/report_Q1.txt"

import pathlib, hashlib, sys

# Adjust this to your actual restore path variable if needed
restore_root = pathlib.Path(RESTORE_DIR)
victim = next(restore_root.rglob("victim_data"), None)
if victim is None:
    print("‚ùå  victim_data not found!"); sys.exit(1)

file = victim / "docs" / "report_Q1.txt"
if not file.exists():
    print("‚ùå  report_Q1.txt missing!"); sys.exit(1)

content = file.read_text()
assert "Quarterly revenue: $123,456" in content, "Content mismatch!"

sha = hashlib.sha256(file.read_bytes()).hexdigest()
print(f"‚úÖ  report_Q1.txt verified ‚Äî SHA‚Äë256: {sha[:12]}‚Ä¶")

"""##Step 14: Compare Original to Restored
Sanity Check
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash -s "$DATA_DIR" "$RESTORE_DIR"
# # $1 is the live data dir, $2 is where Restic put your restore tree
# ORIG="$1"
# RESTORE_ROOT="$2"
# 
# # 2. Locate the restored victim_data under RESTORE_ROOT
# RESTORED_V=$(find "$RESTORE_ROOT" -type d -name victim_data | head -n1)
# if [ -z "$RESTORED_V" ]; then
#   echo "‚ùå  Could not find victim_data under $RESTORE_ROOT"
#   exit 1
# fi
# 
# echo "‚úÖ  Restored data is at: $RESTORED_V"
# echo
# 
# # 3. Compare original vs restored
# echo "Comparing live vs restored:"
# echo "  live:     $ORIG"
# echo "  restored: $RESTORED_V"
# echo
# 
# diff -rq "$ORIG" "$RESTORED_V" \
#   && echo "‚úÖ  No unexpected differences." \
#   || echo "üî∂  Differences above are expected for encrypted docs."

"""##Optional: Prune Workspace
* Locating the deepest nested 'victim_data' directory inside restore_root
* Removing any '.enc' encrypted files
* Moving the restored data to the original victim_data_path
* Deleting all contents of the restore_root directory
"""

import os
import shutil
import pathlib

def finalize_restoration(restore_root: str, victim_data_path: str):
    restore_root = pathlib.Path(restore_root)
    victim_data_path = pathlib.Path(victim_data_path)

    # Locate the deepest nested victim_data directory
    nested_victim_dirs = sorted(restore_root.rglob("victim_data"), key=lambda p: len(str(p)), reverse=True)
    if not nested_victim_dirs:
        print("‚ùå No victim_data directory found in restore root.")
        return False

    restored_victim = nested_victim_dirs[0]
    print(f"‚úÖ Found restored victim_data at: {restored_victim}")

    # Remove encrypted files
    for enc_file in restored_victim.rglob("*.enc"):
        try:
            enc_file.unlink()
            print(f"üóëÔ∏è Deleted encrypted file: {enc_file}")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to delete {enc_file}: {e}")

    # Replace original victim_data with restored version
    if victim_data_path.exists():
        shutil.rmtree(victim_data_path)
    shutil.copytree(restored_victim, victim_data_path)
    print(f"üì¶ Moved restored data to: {victim_data_path}")

    # Delete all contents of the restore_root directory
    for item in restore_root.iterdir():
        try:
            if item.is_dir():
                shutil.rmtree(item)
            else:
                item.unlink()
            print(f"üßπ Deleted: {item}")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to delete {item}: {e}")

    return True

if success:
  finalize_restoration(
      restore_root=RESTORE_DIR,
      victim_data_path=DATA_DIR
  )

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# #!/bin/bash
# 
# # Define the root directory
# VICTIM_PATH="/content/drive/MyDrive/ransomware_lab/victim_data"
# RESTORE_PATH="/content/drive/MyDrive/ransomware_lab/restore"
# 
# # Check if the directory exists
# if [ ! -d "$VICTIM_PATH" ]; then
#   echo "‚ùå Directory not found: $VICTIM_PATH"
#   exit 1
# fi
# if [ ! -d "$RESTORE_PATH" ]; then
#   echo "‚ùå Directory not found: $RESTORE_PATH"
#   exit 1
# fi
# 
# # Print the tree with human-readable sizes
# echo "üìÅ Directory tree for: $VICTIM_PATH"
# echo
# 
# tree -h "$VICTIM_PATH"
# # Print the tree with human-readable sizes
# echo "üìÅ Directory tree for: $RESTORE_PATH"
# echo
# 
# tree -h "$RESTORE_PATH"

time.sleep(10)
print_current_snapshots(RESTIC_REPO)

"""##Step 15: Stop Periodic Baseline"""

import threading
import time

stop_ev.set()
thread.join(timeout=5)
print("üõë Periodic baseline stopped.")